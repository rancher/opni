[{"body":"Opni Monitoring uses Role Based Access Control (RBAC) to control which clusters a given user is allowed to see. If you are familiar with RBAC in Kubernetes, it works the same way.\nIn Kubernetes, RBAC rules are used to determine which API resources a given User or Service Account is allowed to access. Similarly, in Opni Monitoring, RBAC rules are used to determine which clusters a user has access to. When a user makes an authenticated query, the system will evaluate the current RBAC rules for that user and determine which clusters to consider when running the query.\nLabels Clusters in Opni Monitoring have an opaque ID and can have a number of key-value labels. Labels are the primary means of identifying clusters for access control purposes. Labels in Opni Monitoring are functionally similar to labels in Kubernetes, and follow these rules:\n  Labels must have unique keys, and there is a one-to-one mapping between keys and values.\n  Labels cannot have empty keys or values\n  Label keys must match the following regular expression:\n^[a-zA-Z0-9][a-zA-Z0-9-_./]{0,63}$   Label values must match the following regular expression:\n^[a-zA-Z0-9][a-zA-Z0-9-_.]{0,63}$   Roles A role is a named object representing a set of permissions. It contains rules that match clusters by ID or by the cluster‚Äôs labels. A role can use any/all of the following matchers:\n1. Label Matchers A role can match clusters by specifying an explicit key=value label pair that will match a single label with the exact key and value specified. No partial matching or globbing is performed.\n2. Label Selector Expressions A role can also match clusters by using a Kubernetes-style label selector. These selectors are more versatile, and can match labels using a variety of rules, such as:\n Matching if a given key exists Matching if a given key does not exist Matching if the value for a given key is in a list of allowed values Matching if the value for a given key is not in a list of allowed values  3. Explicit Cluster IDs Clusters can also be explicitly added to a role by ID. It is not recommended to use explicit cluster IDs as a primary means of access control, but they can be useful in situations where you want to add an exception to an existing role or a temporary override. Label-based selectors are much more flexible, and should be preferred in general.\nRole Bindings A role binding is a named object that attaches one or more users (‚Äúsubjects‚Äù) to a role. When evaluating RBAC rules for a given user, the system will look up all role bindings attached to that user, then use the union of the associated roles to determine which clusters the user is allowed to see.\n","categories":"","description":"Configuring role-based access to clusters","excerpt":"Configuring role-based access to clusters","ref":"/opni-monitoring/guides/access_control/","tags":"","title":"Access Control"},{"body":"  .td-sidebar-toc { display: none !important; } .diagram { padding-right: 20px; }   var main = document.querySelector('main'); console.log(main) main.classList.remove('col-xl-8'); main.classList.add('col-xl-10');   Components Opni Monitoring Cluster  The Opni Monitoring cluster is the cluster in which the Opni Monitoring control-plane components are installed. This is the central cluster where all downstream clusters send their metrics to. Deployed in this cluster are the following components:   Opni Gateway   Cortex   Grafana   Etcd   (optional) Opni Agent   Downstream Clusters  Downstream clusters are the clusters that send their metrics to the Opni Monitoring cluster. Deployed in these clusters are the following components:   Opni Agent   Prometheus Agent   OpenID Provider  A production deployment of Opni Monitoring must use an OpenID Provider to authenticate users. The Grafana dashboard deployed in the Opni Monitoring cluster will be configured to use the OpenID Provider for user login. Support for other authentication mechanisms (LDAP, SAML, etc.) may be added in the future. Long-Term Storage  A production deployment of Opni Monitoring should be configured to use long-term metric storage. For example, this could be an S3-compatible object storage service. ","categories":"","description":"","excerpt":"  .td-sidebar-toc { display: none !important; } .diagram { ‚Ä¶","ref":"/opni-monitoring/architecture/","tags":"","title":""},{"body":"Opni Monitoring supports OpenID Connect for generic user authentication and authorization. Any OpenID Connect provider can be used.\nConfigure your OpenID Provider  Create a new client ID and secret. Set an allowed callback URL to https://grafana.\u003cgateway_address\u003e/login/generic_oauth Set an allowed logout URL to https://grafana.\u003cgateway_address\u003e  Edit Opni Monitoring configuration  Edit deploy/custom/opni-monitoring.yaml as follows:  auth:provider:openidopenid:// discovery and wellKnownConfiguration are mutually exclusive.// If the OP (openid provider) has a discovery endpoint, it should be// configured in the discovery field, otherwise the well-known configuration// fields can be set manually. If set, required fields are listed below.discovery:// Relative path at which to find the openid configuration.// Defaults to \"/.well-known/openid-configuration\".path:\"/.well-known/openid-configuration\"// The OP's Issuer identifier. This must exactly match the issuer URL// obtained from the discovery endpoint, and will match the `iss' claim// in the ID Tokens issued by the OP.issuer:\"\"# required// Optional manually-provided discovery information. Mutually exclusive with // the discovery field (see above). If set, required fields are listed below.wellKnownConfiguration:issuer:\"\"# requiredauthorization_endpoint:\"\"# requiredtoken_endpoint:\"\"# requireduserinfo_endpoint:\"\"# requiredrevocation_endpoint:\"\"jwks_uri:\"\"# requiredscopes_supported:[]response_types_supported:[]response_modes_supported:[]id_token_signing_alg_values_supported:[]token_endpoint_auth_methods_supported:[]claims_supported:[]request_uri_parameter_supported:false// The ID Token claim that will be used to identify users (\"sub\", \"email\", etc.). // The value of this field will be matched against role binding subject names.// Defaults to \"sub\".identifyingClaim:\"sub\"Edit deploy/custom/grafana.yaml according to the documentation at https://grafana.com/docs/grafana/latest/auth/generic-oauth  grafana.ini:auth.generic_oauth:client_id:client_secret:auth_url:token_url:api_url:signout_redirect_url:allowed_domains:role_attribute_path:use_pkce:","categories":"","description":"Using OpenID Connect with Opni Monitoring","excerpt":"Using OpenID Connect with Opni Monitoring","ref":"/opni-monitoring/authentication/oidc/","tags":"","title":"OpenID Connect"},{"body":"It is important to understand the following terms and phrases before you get started with Opni Monitoring:\nMulti-Cluster Multi-Cluster (as in ‚Äúmulti-cluster monitoring‚Äù) refers to operations that involve multiple independent Kubernetes clusters.\nMulti-Tenant/Multi-Tenancy A tenant refers to a user or group of users who share a common access with specific privileges to the software/data instance.\nIn the context of Opni Monitoring, ‚Äúmulti-tenancy‚Äù refers to the feature that allows multiple users to each have access to a different arbitrary subset of all available data.\nImportant In the Cortex documentation, the terms ‚Äútenant‚Äù, ‚Äúuser‚Äù, and ‚Äúorg‚Äù are used interchangeably, and all refer to what Opni Monitoring calls ‚Äúclusters‚Äù.\nIn Cortex terminology, ‚Äúmulti-tenancy‚Äù refers to the ability to federate a single request across multiple [cortex] tenants (where ‚Äúfederation‚Äù refers to the aggregation of the results of several individual requests to appear as one).\n (Main|Upstream|Opni Monitoring) Cluster ‚ÄúMain Cluster‚Äù, ‚ÄúUpstream Cluster‚Äù, and ‚ÄúOpni Monitoring Cluster‚Äù all refer to the cluster where Opni Gateway, Cortex, and Grafana are installed. Metrics from all clusters are sent to the Opni Gateway in this cluster, and are processed and stored by Cortex.\nDownstream Cluster This refers to a cluster running the Opni Agent and Prometheus Agent which sends all its metrics (using Prometheus Remote-Write) to the main cluster.\nNote The Opni Agent and Prometheus Agent are often also installed into the main cluster, to scrape metrics from the Opni Gateway and Cortex. However, we would still refer to that cluster as the main cluster.  ","categories":"","description":"Definitions of commonly used terms and phrases","excerpt":"Definitions of commonly used terms and phrases","ref":"/opni-monitoring/reference/terminology/","tags":"","title":"Terminology"},{"body":"This guide will walk you through installing Opni Monitoring and adding clusters to the system. Before proceeding, please read the section on Terminology to familiarize yourself with a few key terms.\nPrerequisites Infrastructure   One main cluster where the Opni Monitoring control-plane components will be installed. The main cluster must be accessible to all downstream clusters.\n  One or more downstream clusters which will be configured to send metrics to the main cluster\n  A domain name or subdomain at which to host the Opni Gateway public API. For a demo or testing installation, you can use sslip.io. In the rest of this guide, the domain name will be referred to as \u003cgateway_address\u003e.\n  All clusters must have a default storage class available.\n  Dependencies   helm version 3.8 or later\n  helm-diff plugin, which can be installed with the following command:\n$ helm plugin install https://github.com/databus23/helm-diff   helmfile, which can be installed using your distribution‚Äôs package manager or from the GitHub release page.\n  Setting up the main cluster First, clone the opni-monitoring repo:\n$ git clone https://github.com/rancher/opni Ensure you are running helm version 3.8 or later:\n$ helm version version.BuildInfo{Version:\"v3.8.1\", GitCommit:\"5cb9af4b1b271d11d7a97a71df3ac337dd94ad37\", GitTreeState:\"clean\", GoVersion:\"go1.17.8\"} Chart configuration Inside the opni-monitoring repo, there are a few template yaml files in deploy/custom which you will need to copy and edit before continuing. These files will be used to configure authentication and Cortex long-term storage.\n1. Authentication  For a demo or testing installation, follow the instructions in the Demo Auth section. For a production installation, follow the instructions in the OpenID Connect section.  2. Cortex   For a demo or testing installation, you can create an empty deploy/custom/cortex.yaml file to use the default configuration.\n  For a production installation, edit deploy/custom/cortex.yaml using the template as reference and the Cortex docs.\n  Chart Installation Inside the opni-monitoring repo, change directories to deploy/.\n Ensure your current kubeconfig points to the main cluster. Run helmfile apply Wait for all resources to become ready. This may take a few minutes.  DNS Configuration  Identify the external IP of the opni-monitoring load balancer. Configure A records such that \u003cgateway_address\u003e and grafana.\u003cgateway_address\u003e both resolve to the IP address of the load balancer (skip this step if you are using sslip.io or a similar service).  Accessing the dashboard Once all the pods in the opni-monitoring namespace are running, open the web dashboard:\n Port-forward to the opni-monitoring-internal service:  kubectl -n opni-monitoring port-forward svc/opni-monitoring-internal management-web:management-web Open your browser to http://localhost:12080.   Next Steps This section is optional, but highly recommended.\nAdding a cluster First, let‚Äôs add the main cluster itself - this allows us to gather metrics from the Opni Gateway and Cortex. Follow these steps to add the cluster to Opni Monitoring:\nCreate a token Tokens are used to authenticate new clusters during the bootstrap process. To create one:\n Navigate to the Tokens tab in the sidebar Click Create Token Use the default fields, and click Create. The new token will appear in the table.  Token Expiration All tokens will expire after a certain amount of time. The default value is 10 minutes, but you can choose any duration you like. If your token expires, you can simply create a new one.  Add a cluster  Navigate to the Clusters tab in the sidebar Click Add Cluster In the Capabilities drop-down menu, select metrics In the Token drop-down menu, select the token we just created. When a capability and token have been selected, an install command will appear below. Check the box that says Install Prometheus Operator (however, if you already have Prometheus Operator installed on a cluster you want to add, leave it unchecked). Click on the install command to copy it to the clipboard In a terminal, ensure your KUBECONFIG environment variable or ~/.kube/config context points to the cluster you want to add (in this case, the main cluster), then paste and run the command. In a few seconds, you should see a green banner informing you that the cluster has been added. If you want to add any additional clusters right now, you can repeat step 7 for each cluster using the same command you copied previously. Click Finish to return to the cluster list.   Further Reading Read the section on Access Control to learn how to configure roles and role bindings. Then, head to https://grafana.\u003cgateway_address\u003e in your browser to sign in.\nCheck out the Guides section for more. Happy monitoring!\n","categories":"","description":"","excerpt":"This guide will walk you through installing Opni Monitoring and adding ‚Ä¶","ref":"/opni-monitoring/installation/","tags":"","title":"Installation"},{"body":"Cluster Capabilities Each cluster in Opni Monitoring has a set of capabilities that correspond to the high-level features available to that cluster. Currently, there are two capabilities: metrics and logs. A cluster can have one or both of these capabilities. When adding a cluster, depending on the capability you select, different features will be available.\nAdding a new cluster Prerequisites  The new cluster must be able to reach the Opni Gateway API endpoint. You have previously created a token to use for the new cluster. Reusing the same token for multiple clusters is fine, as long as it has not yet expired.  Installation Adding a new downstream cluster will require installing Kubernetes resources in that cluster. Different capabilities will install different resources. Use the Opni Monitoring dashboard to set up the new cluster by following the steps below:\n Navigate to the Clusters tab in the sidebar Click Add Cluster In the Capabilities drop-down menu, select the capability you want to install. Choose an available token from the Token drop-down menu. When a capability and token have been selected, an install command will appear below. This command will be specific to the selected capability. Depending on the selected capability, some options may appear in the UI above the install command. Changing these options will adjust the install command in some way. If any options are marked with a red asterisk, that indicates the option is required. Click on the install command to copy it to the clipboard. In a terminal, ensure your KUBECONFIG environment variable or ~/.kube/config context points to the new cluster, then paste and run the command. In a few seconds, you should see a green banner informing you that the cluster has been added. Click Finish to return to the cluster list.  Adding a new capability to an existing cluster The process of adding a new capability to an already existing cluster is similar to the process of adding a new cluster. The main difference is that there are additional requirements for the token you choose.\nJoin Tokens When a token is used to add a cluster, the token permanently gains the join capability for that cluster. This can be seen in the tokens list after adding a cluster. The capability is displayed in the UI as join: followed by the first 8 characters of the cluster ID. A token with the join capability for a cluster may be used to add additional capabilities to that cluster.\nIf the token originally used to create the cluster expired or was deleted, you can create a new join token in the UI. To do this:\n Navigate to the Tokens tab in the sidebar Click Create Token Under ‚ÄúExtended Capabilities‚Äù, select Join Existing Cluster, then click Create. The new token will be created with the join capability for the cluster you selected.  Deleting a cluster To remove a cluster from Opni Monitoring, select the cluster or clusters you wish to delete from the clusters list and click Delete. Once deleted, the downstream cluster will no longer have permissions to access the Opni Gateway API and forward metrics or other data.\nCurrently, the following limitations apply with regards to deleting clusters:\n Deleting a cluster will not delete any of its stored metrics. Deleting a cluster will not uninstall any resources from the downstream Kubernetes cluster.  Cleaning up a deleted Cluster To clean up Kubernetes resources in a deleted downstream cluster, simply delete the opni-monitoring-agent namespace. It may take a while for all resources in the namespace to be fully deleted.\nAlternatively, uninstalling the opni-monitoring-agent helm chart and deleting the keyring-agent-\u003ccluster-id\u003e secret will have the same effect.\n","categories":"","description":"Creating and deleting clusters, and adding capabilities to existing clusters","excerpt":"Creating and deleting clusters, and adding capabilities to existing ‚Ä¶","ref":"/opni-monitoring/guides/clusters/","tags":"","title":"Managing Clusters"},{"body":"","categories":"","description":"","excerpt":"","ref":"/opni-monitoring/guides/","tags":"","title":"Guides"},{"body":"","categories":"","description":"Configuring user authentication","excerpt":"Configuring user authentication","ref":"/opni-monitoring/authentication/","tags":"","title":"Authentication"},{"body":"","categories":"","description":"","excerpt":"","ref":"/opni-monitoring/reference/","tags":["reference"],"title":"Reference"},{"body":"The noauth auth provider can be used for demo purposes or for testing.\nHow it works This demo auth mechanism allows Opni Monitoring to be its own OpenID Provider. When signing in to Grafana, instead of being redirected to an external OAuth provider, you will be redirected to a simple login page containing a list of all known users in the system (the set of all subjects in the current list of role bindings). Simply select the user you want to sign in as and you will be redirected back to Grafana, logged in as that user. All users will be a Grafana admin.\nConfiguration  Edit deploy/custom/grafana.yaml as follows, substituting \u003cgateway_address\u003e for the public DNS name of your main cluster or load balancer:  grafana.ini:server:domain:\"grafana.\u003cgateway_address\u003e\"root_url:\"https://grafana.\u003cgateway_address\u003e\"auth.generic_oauth:client_id:\"grafana\"client_secret:\"supersecret\"# (this can be whatever you want)auth_url:\"http://\u003cgateway_address\u003e:4000/oauth2/authorize\"token_url:\"http://\u003cgateway_address\u003e:4000/oauth2/token\"api_url:\"http://\u003cgateway_address\u003e:4000/oauth2/userinfo\"allowed_domains:example.com# (this can be whatever you want, but remember it for later)role_attribute_path:grafana_roleuse_pkce:falsetls:- secretName:grafana-tls-keyshosts:- \"grafana.\u003cgateway_address\u003e\"ingress:enabled:truehosts:- \"grafana.\u003cgateway_address\u003e\"Edit deploy/custom/opni-monitoring.yaml as follows, substituting \u003cgateway_address\u003e:  auth:provider:noauthnoauth:discovery:issuer:\"http://\u003cgateway_address\u003e:4000/oauth2\"clientID:grafanaclientSecret:supersecret# (this must match client_secret in grafana.yaml)redirectURI:\"https://grafana.\u003cgateway_address\u003e/login/generic_oauth\"managementAPIEndpoint:\"opni-monitoring-internal:11090\"port:4000gateway:hostname:\"\u003cgateway_address\u003e\"dnsNames:- \"\u003cgateway_address\u003e\"","categories":"","description":"Configure a demo authentication provider","excerpt":"Configure a demo authentication provider","ref":"/opni-monitoring/authentication/noauth/","tags":"","title":"Demo Auth"},{"body":"Opni Monitoring is an open-source multi-cluster monitoring system. It ingests Prometheus metrics from any number of Kubernetes clusters and provides a centralized observability plane for your infrastructure. Use Opni Monitoring to visualize metrics from all your clusters at once, and give every user their own customized view using granular access control.\n‚ö° Powered by Open-Source Opni Monitoring is completely free Apache-licensed open-source software. It builds upon existing, ubiquitous open-source systems - Prometheus, Grafana, and Cortex - and extends them with a number of powerful enterprise features typically only found in SaaS platforms and other proprietery solutions.\nüîã Batteries Included Opni Monitoring comes out of the box with all the tools you need to get started with multi-cluster monitoring. Manage your clusters and configure access control rules with the built-in dashboard, command-line interface, or REST API.\nOpni Monitoring is secure-by-default and uses a zero-trust architecture for inter-cluster communication, with no extra setup required.\nüîí You Own Your Data With Opni Monitoring, you have complete control over how and where your data is stored. Metric storage is powered by Cortex, which provides comprehensive configuration options for data storage and retention. Several storage backends are available including S3 (cloud or self-hosted), Swift, and Kubernetes Persistent Volumes.\nGet Started  See Installation for instructions on how to set up Opni Monitoring. Take a look at the Architecture Overview for details on how Opni Monitoring works.  ","categories":"","description":"","excerpt":"Opni Monitoring is an open-source multi-cluster monitoring system. It ‚Ä¶","ref":"/opni-monitoring/","tags":"","title":""},{"body":"","categories":"","description":"","excerpt":"","ref":"/opni-monitoring/categories/","tags":"","title":"Categories"},{"body":"","categories":"","description":"","excerpt":"","ref":"/opni-monitoring/tags/reference/","tags":"","title":"reference"},{"body":"","categories":"","description":"","excerpt":"","ref":"/opni-monitoring/search/","tags":"","title":"Search Results"},{"body":"","categories":"","description":"","excerpt":"","ref":"/opni-monitoring/tags/","tags":"","title":"Tags"}]