// Code generated by internal/codegen. You may edit parts of this file.
// Field numbers and custom options will be preserved for matching field names.
// All other modifications will be lost.
syntax = "proto3";
package validation;

import "github.com/rancher/opni/internal/codegen/cli/cli.proto";
import "google/protobuf/duration.proto";

option go_package      = "github.com/rancher/opni/internal/cortex/config/validation";
option (cli.generator) = {
  generate:          true
  generate_deepcopy: true
};

message Limits {
  // Per-user ingestion rate limit in samples per second.
  optional double ingestion_rate = 1 [(cli.flag) = {default: "25000"}];
  // Whether the ingestion rate limit should be applied individually to each distributor instance (local), or evenly shared across the cluster (global).
  optional string ingestion_rate_strategy = 2 [(cli.flag) = {default: "local"}];
  // Per-user allowed ingestion burst size (in number of samples).
  optional int32 ingestion_burst_size = 3 [(cli.flag) = {default: "50000"}];
  // Flag to enable, for all users, handling of samples with external labels identifying replicas in an HA Prometheus setup.
  optional bool accept_ha_samples = 4 [(cli.flag) = {default: "false"}];
  // Prometheus label to look for in samples to identify a Prometheus HA cluster.
  optional string ha_cluster_label = 5 [(cli.flag) = {default: "cluster"}];
  // Prometheus label to look for in samples to identify a Prometheus HA replica.
  optional string ha_replica_label = 6 [(cli.flag) = {default: "__replica__"}];
  // Maximum number of clusters that HA tracker will keep track of for single user. 0 to disable the limit.
  optional int32 ha_max_clusters = 7 [(cli.flag) = {default: "0"}];
  // This flag can be used to specify label names that to drop during sample ingestion within the distributor and can be repeated in order to drop multiple labels.
  repeated string drop_labels = 8 [(cli.flag) = {default: "[]"}];
  // Maximum length accepted for label names
  optional int32 max_label_name_length = 9 [(cli.flag) = {default: "1024"}];
  // Maximum length accepted for label value. This setting also applies to the metric name
  optional int32 max_label_value_length = 10 [(cli.flag) = {default: "2048"}];
  // Maximum number of label names per series.
  optional int32 max_label_names_per_series = 11 [(cli.flag) = {default: "30"}];
  // Maximum combined size in bytes of all labels and label values accepted for a series. 0 to disable the limit.
  optional int32 max_labels_size_bytes = 12 [(cli.flag) = {default: "0"}];
  // Maximum length accepted for metric metadata. Metadata refers to Metric Name, HELP and UNIT.
  optional int32 max_metadata_length = 13 [(cli.flag) = {default: "1024"}];
  // Reject old samples.
  optional bool reject_old_samples = 14 [(cli.flag) = {default: "false"}];
  // Maximum accepted sample age before rejecting.
  google.protobuf.Duration reject_old_samples_max_age = 15 [(cli.flag) = {default: "2w"}];
  // Duration which table will be created/deleted before/after it's needed; we won't accept sample from before this time.
  google.protobuf.Duration creation_grace_period = 16 [(cli.flag) = {default: "10m"}];
  // Enforce every metadata has a metric name.
  optional bool enforce_metadata_metric_name = 17 [(cli.flag) = {default: "true"}];
  // Enforce every sample has a metric name.
  optional bool enforce_metric_name = 18 [(cli.flag) = {default: "true"}];
  // The default tenant's shard size when the shuffle-sharding strategy is used. Must be set both on ingesters and distributors. When this setting is specified in the per-tenant overrides, a value of 0 disables shuffle sharding for the tenant.
  optional int32 ingestion_tenant_shard_size = 19 [(cli.flag) = {default: "0"}];
  // List of metric relabel configurations. Note that in most situations, it is more effective to use metrics relabeling directly in the Prometheus server, e.g. remote_write.write_relabel_configs.
  repeated RelabelConfig metric_relabel_configs = 20 [(cli.flag) = {skip: true}];
  // Enables support for exemplars in TSDB and sets the maximum number that will be stored. less than zero means disabled. If the value is set to zero, cortex will fallback to blocks-storage.tsdb.max-exemplars value.
  optional int32 max_exemplars = 21 [(cli.flag) = {default: "0"}];
  // The maximum number of series for which a query can fetch samples from each ingester. This limit is enforced only in the ingesters (when querying samples not flushed to the storage yet) and it's a per-instance limit. This limit is ignored when running the Cortex blocks storage. When running Cortex with blocks storage use -querier.max-fetched-series-per-query limit instead.
  optional int32 max_series_per_query = 22 [(cli.flag) = {default: "100000"}];
  // The maximum number of active series per user, per ingester. 0 to disable.
  optional int32 max_series_per_user = 23 [(cli.flag) = {default: "5000000"}];
  // The maximum number of active series per metric name, per ingester. 0 to disable.
  optional int32 max_series_per_metric = 24 [(cli.flag) = {default: "50000"}];
  // The maximum number of active series per user, across the cluster before replication. 0 to disable. Supported only if -distributor.shard-by-all-labels is true.
  optional int32 max_global_series_per_user = 25 [(cli.flag) = {default: "0"}];
  // The maximum number of active series per metric name, across the cluster before replication. 0 to disable.
  optional int32 max_global_series_per_metric = 26 [(cli.flag) = {default: "0"}];
  // The maximum number of active metrics with metadata per user, per ingester. 0 to disable.
  optional int32 max_metadata_per_user = 27 [(cli.flag) = {default: "8000"}];
  // The maximum number of metadata per metric, per ingester. 0 to disable.
  optional int32 max_metadata_per_metric = 28 [(cli.flag) = {default: "10"}];
  // The maximum number of active metrics with metadata per user, across the cluster. 0 to disable. Supported only if -distributor.shard-by-all-labels is true.
  optional int32 max_global_metadata_per_user = 29 [(cli.flag) = {default: "0"}];
  // The maximum number of metadata per metric, across the cluster. 0 to disable.
  optional int32 max_global_metadata_per_metric = 30 [(cli.flag) = {default: "0"}];
  // [Experimental] Configures the allowed time window for ingestion of out-of-order samples. Disabled (0s) by default.
  google.protobuf.Duration out_of_order_time_window = 31 [(cli.flag) = {default: "0s"}];
  // Maximum number of chunks that can be fetched in a single query from ingesters and long-term storage. This limit is enforced in the querier, ruler and store-gateway. 0 to disable.
  optional int32 max_fetched_chunks_per_query = 32 [(cli.flag) = {default: "2000000"}];
  // The maximum number of unique series for which a query can fetch samples from each ingesters and blocks storage. This limit is enforced in the querier, ruler and store-gateway. 0 to disable
  optional int32 max_fetched_series_per_query = 33 [(cli.flag) = {default: "0"}];
  // Deprecated (use max-fetched-data-bytes-per-query instead): The maximum size of all chunks in bytes that a query can fetch from each ingester and storage. This limit is enforced in the querier, ruler and store-gateway. 0 to disable.
  optional int32 max_fetched_chunk_bytes_per_query = 34 [(cli.flag) = {default: "0"}];
  // The maximum combined size of all data that a query can fetch from each ingester and storage. This limit is enforced in the querier and ruler for `query`, `query_range` and `series` APIs. 0 to disable.
  optional int32 max_fetched_data_bytes_per_query = 35 [(cli.flag) = {default: "0"}];
  // Limit how long back data (series and metadata) can be queried, up until <lookback> duration ago. This limit is enforced in the query-frontend, querier and ruler. If the requested time range is outside the allowed range, the request will not fail but will be manipulated to only query data within the allowed time range. 0 to disable.
  google.protobuf.Duration max_query_lookback = 36 [(cli.flag) = {default: "0s"}];
  // Limit the query time range (end - start time). This limit is enforced in the query-frontend (on the received query) and in the querier (on the query possibly split by the query-frontend). 0 to disable.
  google.protobuf.Duration max_query_length = 37 [(cli.flag) = {default: "0s"}];
  // Maximum number of split queries will be scheduled in parallel by the frontend.
  optional int32 max_query_parallelism = 38 [(cli.flag) = {default: "14"}];
  // Most recent allowed cacheable result per-tenant, to prevent caching very recent results that might still be in flux.
  google.protobuf.Duration max_cache_freshness = 39 [(cli.flag) = {default: "1m"}];
  // Maximum number of queriers that can handle requests for a single tenant. If set to 0 or value higher than number of available queriers, *all* queriers will handle requests for the tenant. If the value is < 1, it will be treated as a percentage and the gets a percentage of the total queriers. Each frontend (or query-scheduler, if used) will select the same set of queriers for the same tenant (given that all queriers are connected to all frontends / query-schedulers). This option only works with queriers connecting to the query-frontend / query-scheduler, not when using downstream URL.
  optional double max_queriers_per_tenant = 40 [(cli.flag) = {default: "0"}];
  // Maximum number of outstanding requests per tenant per request queue (either query frontend or query scheduler); requests beyond this error with HTTP 429.
  optional int32 max_outstanding_requests_per_tenant = 41 [(cli.flag) = {default: "100"}];
  // Duration to delay the evaluation of rules to ensure the underlying metrics have been pushed to Cortex.
  google.protobuf.Duration ruler_evaluation_delay_duration = 42 [(cli.flag) = {default: "0s"}];
  // The default tenant's shard size when the shuffle-sharding strategy is used by ruler. When this setting is specified in the per-tenant overrides, a value of 0 disables shuffle sharding for the tenant.
  optional int32 ruler_tenant_shard_size = 43 [(cli.flag) = {default: "0"}];
  // Maximum number of rules per rule group per-tenant. 0 to disable.
  optional int32 ruler_max_rules_per_rule_group = 44 [(cli.flag) = {default: "0"}];
  // Maximum number of rule groups per-tenant. 0 to disable.
  optional int32 ruler_max_rule_groups_per_tenant = 45 [(cli.flag) = {default: "0"}];
  // The default tenant's shard size when the shuffle-sharding strategy is used. Must be set when the store-gateway sharding is enabled with the shuffle-sharding strategy. When this setting is specified in the per-tenant overrides, a value of 0 disables shuffle sharding for the tenant. If the value is < 1 the shard size will be a percentage of the total store-gateways.
  optional double store_gateway_tenant_shard_size = 46 [(cli.flag) = {default: "0"}];
  // The maximum number of data bytes to download per gRPC request in Store Gateway, including Series/LabelNames/LabelValues requests. 0 to disable.
  optional int32 max_downloaded_bytes_per_request = 47 [(cli.flag) = {default: "0"}];
  // Delete blocks containing samples older than the specified retention period. 0 to disable.
  google.protobuf.Duration compactor_blocks_retention_period = 48 [(cli.flag) = {default: "0s"}];
  // The default tenant's shard size when the shuffle-sharding strategy is used by the compactor. When this setting is specified in the per-tenant overrides, a value of 0 disables shuffle sharding for the tenant.
  optional int32 compactor_tenant_shard_size = 49 [(cli.flag) = {default: "0"}];
  // S3 server-side encryption type. Required to enable server-side encryption overrides for a specific tenant. If not set, the default S3 client settings are used.
  optional string s3_sse_type = 50 [(cli.flag) = {skip: true}];
  // S3 server-side encryption KMS Key ID. Ignored if the SSE type override is not set.
  optional string s3_sse_kms_key_id = 51 [(cli.flag) = {skip: true}];
  // S3 server-side encryption KMS encryption context. If unset and the key ID override is set, the encryption context will not be provided to S3. Ignored if the SSE type override is not set.
  optional string s3_sse_kms_encryption_context = 52 [(cli.flag) = {skip: true}];
  // Comma-separated list of network CIDRs to block in Alertmanager receiver integrations.
  repeated string alertmanager_receivers_firewall_block_cidr_networks = 53 [(cli.flag) = {type_override: "ipNet"}];
  // True to block private and local addresses in Alertmanager receiver integrations. It blocks private addresses defined by  RFC 1918 (IPv4 addresses) and RFC 4193 (IPv6 addresses), as well as loopback, local unicast and local multicast addresses.
  optional bool alertmanager_receivers_firewall_block_private_addresses = 54 [(cli.flag) = {default: "false"}];
  // Per-user rate limit for sending notifications from Alertmanager in notifications/sec. 0 = rate limit disabled. Negative value = no notifications are allowed.
  optional double alertmanager_notification_rate_limit = 55 [(cli.flag) = {default: "0"}];
  // Per-integration notification rate limits. Value is a map, where each key is integration name and value is a rate-limit (float). On command line, this map is given in JSON format. Rate limit has the same meaning as -alertmanager.notification-rate-limit, but only applies for specific integration. Allowed integration names: webhook, email, pagerduty, opsgenie, wechat, slack, victorops, pushover, sns, telegram, discord, webex, msteams.
  map<string, double> alertmanager_notification_rate_limit_per_integration = 56 [(cli.flag) = {default: "{}"}];
  // Maximum size of configuration file for Alertmanager that tenant can upload via Alertmanager API. 0 = no limit.
  optional int32 alertmanager_max_config_size_bytes = 57 [(cli.flag) = {default: "0"}];
  // Maximum number of templates in tenant's Alertmanager configuration uploaded via Alertmanager API. 0 = no limit.
  optional int32 alertmanager_max_templates_count = 58 [(cli.flag) = {default: "0"}];
  // Maximum size of single template in tenant's Alertmanager configuration uploaded via Alertmanager API. 0 = no limit.
  optional int32 alertmanager_max_template_size_bytes = 59 [(cli.flag) = {default: "0"}];
  // Maximum number of aggregation groups in Alertmanager's dispatcher that a tenant can have. Each active aggregation group uses single goroutine. When the limit is reached, dispatcher will not dispatch alerts that belong to additional aggregation groups, but existing groups will keep working properly. 0 = no limit.
  optional int32 alertmanager_max_dispatcher_aggregation_groups = 60 [(cli.flag) = {default: "0"}];
  // Maximum number of alerts that a single user can have. Inserting more alerts will fail with a log message and metric increment. 0 = no limit.
  optional int32 alertmanager_max_alerts_count = 61 [(cli.flag) = {default: "0"}];
  // Maximum total size of alerts that a single user can have, alert size is the sum of the bytes of its labels, annotations and generatorURL. Inserting more alerts will fail with a log message and metric increment. 0 = no limit.
  optional int32 alertmanager_max_alerts_size_bytes = 62 [(cli.flag) = {default: "0"}];
  // list of rule groups to disable
  repeated DisabledRuleGroup disabled_rule_groups = 63 [(cli.flag) = {skip: true}];
}

message DisabledRuleGroup {
  // namespace in which the rule group belongs
  optional string namespace = 1 [(cli.flag) = {skip: true}];
  // name of the rule group
  optional string name = 2 [(cli.flag) = {skip: true}];
}

message RelabelConfig {
  repeated string source_labels = 1;
  optional string separator     = 2;
  string          regex         = 3;
  optional uint64 modulus       = 4;
  optional string target_label  = 5;
  optional string replacement   = 6;
  optional string action        = 7;
}
